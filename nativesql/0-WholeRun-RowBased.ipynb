{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Query 1 #####################\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master('yarn-client')\\\n",
    "        .appName(\"TPCH_Q1\")\\\n",
    "        .getOrCreate()\n",
    "df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/lineitem\")\n",
    "df.createOrReplaceTempView(\"lineitem\")\n",
    "query = \"select \\\n",
    "           l_returnflag, \\\n",
    "           l_linestatus, \\\n",
    "           sum(l_quantity) as sum_qty, \\\n",
    "           sum(l_extendedprice) as sum_base_price, \\\n",
    "           sum(l_extendedprice * (1 - l_discount)) as sum_disc_price, \\\n",
    "           sum(l_extendedprice * (1 - l_discount) * (1 + l_tax)) as sum_charge, \\\n",
    "           avg(l_quantity) as avg_qty, \\\n",
    "           avg(l_extendedprice) as avg_price, \\\n",
    "           avg(l_discount) as avg_disc, \\\n",
    "           count(*) as count_order \\\n",
    "        from \\\n",
    "          lineitem \\\n",
    "        where \\\n",
    "          l_shipdate <= date '1998-09-02' \\\n",
    "        group by \\\n",
    "          l_returnflag, l_linestatus \\\n",
    "        order by \\\n",
    "          l_returnflag, l_linestatus\"\n",
    "sqlDF = spark.sql(query)\n",
    "print(\"RowBased Process\")\n",
    "%time sqlDF.show()\n",
    "%time sqlDF.show()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Query 2 #####################\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master('yarn-client')\\\n",
    "        .appName(\"TPCH_Q2\")\\\n",
    "        .getOrCreate()\n",
    "p_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/part\")\n",
    "p_df.createOrReplaceTempView(\"part\")\n",
    "s_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/supplier\")\n",
    "s_df.createOrReplaceTempView(\"supplier\")\n",
    "ps_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/partsupp\")\n",
    "ps_df.createOrReplaceTempView(\"partsupp\")\n",
    "n_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/nation\")\n",
    "n_df.createOrReplaceTempView(\"nation\")\n",
    "r_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/region\")\n",
    "r_df.createOrReplaceTempView(\"region\")\n",
    "query = \"select \\\n",
    "           s_acctbal, \\\n",
    "           s_name, \\\n",
    "           n_name, \\\n",
    "           p_partkey, \\\n",
    "           ps_supplycost, \\\n",
    "           p_mfgr, \\\n",
    "           s_address, \\\n",
    "           s_phone, \\\n",
    "           s_comment \\\n",
    "         from \\\n",
    "           part, \\\n",
    "           supplier, \\\n",
    "           partsupp, \\\n",
    "           nation, \\\n",
    "           region \\\n",
    "         where \\\n",
    "           p_partkey = ps_partkey \\\n",
    "           and s_suppkey = ps_suppkey \\\n",
    "           and p_size = 15 \\\n",
    "           and p_type like '%BRASS' \\\n",
    "           and s_nationkey = n_nationkey \\\n",
    "           and n_regionkey = r_regionkey \\\n",
    "           and r_name = 'EUROPE' \\\n",
    "           and ps_supplycost = ( \\\n",
    "             select \\\n",
    "               min(ps_supplycost) \\\n",
    "             from \\\n",
    "               partsupp, \\\n",
    "               supplier, \\\n",
    "               nation, \\\n",
    "               region \\\n",
    "             where \\\n",
    "               p_partkey = ps_partkey \\\n",
    "               and s_suppkey = ps_suppkey \\\n",
    "               and s_nationkey = n_nationkey \\\n",
    "               and n_regionkey = r_regionkey \\\n",
    "               and r_name = 'EUROPE') \\\n",
    "         order by \\\n",
    "           s_acctbal desc, n_name, s_name, p_partkey\"\n",
    "sqlDF = spark.sql(query)\n",
    "print(\"RowBased Process\")\n",
    "%time sqlDF.show(100)\n",
    "#%time sqlDF.show(100)\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Query 3 #####################\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master('yarn-client')\\\n",
    "        .appName(\"TPCH_Q3\")\\\n",
    "        .getOrCreate()\n",
    "c_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/customer\")\n",
    "c_df.createOrReplaceTempView(\"customer\")\n",
    "o_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/orders\")\n",
    "o_df.createOrReplaceTempView(\"orders\")\n",
    "l_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/lineitem\")\n",
    "l_df.createOrReplaceTempView(\"lineitem\")\n",
    "query = \"select \\\n",
    "           l_orderkey, \\\n",
    "           sum(l_extendedprice * (1 - l_discount)) as revenue, \\\n",
    "           o_orderdate, \\\n",
    "           o_shippriority \\\n",
    "         from \\\n",
    "           customer, orders, lineitem \\\n",
    "         where \\\n",
    "           c_mktsegment = 'BUILDING' \\\n",
    "           and c_custkey = o_custkey \\\n",
    "           and l_orderkey = o_orderkey \\\n",
    "           and o_orderdate < date '1995-03-15' \\\n",
    "           and l_shipdate > date '1995-03-15' \\\n",
    "         group by \\\n",
    "           l_orderkey, o_orderdate, o_shippriority \\\n",
    "         order by \\\n",
    "           revenue desc, o_orderdate\"\n",
    "sqlDF = spark.sql(query)\n",
    "print(\"RowBased Process\")\n",
    "%time sqlDF.show(10)\n",
    "%time sqlDF.show(10)\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Query 4 #####################\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master('yarn-client')\\\n",
    "        .appName(\"TPCH_Q4\")\\\n",
    "        .getOrCreate()\n",
    "orders_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/orders\")\n",
    "df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/lineitem\")\n",
    "orders_df.createOrReplaceTempView(\"orders\")\n",
    "df.createOrReplaceTempView(\"lineitem\")\n",
    "query = \"select \\\n",
    "           o_orderpriority, \\\n",
    "           count(*) as order_count \\\n",
    "         from \\\n",
    "           orders \\\n",
    "         where \\\n",
    "           o_orderdate >= date '1993-07-01' \\\n",
    "           and o_orderdate < date '1993-10-01' \\\n",
    "           and exists \\\n",
    "           (select * \\\n",
    "            from \\\n",
    "              lineitem \\\n",
    "            where \\\n",
    "              l_orderkey = o_orderkey \\\n",
    "              and l_commitdate < l_receiptdate) \\\n",
    "         group by \\\n",
    "           o_orderpriority \\\n",
    "         order by \\\n",
    "           o_orderpriority\"\n",
    "sqlDF = spark.sql(query)\n",
    "print(\"RowBased Process\")\n",
    "%time sqlDF.show()\n",
    "%time sqlDF.show()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Query 5 #####################\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master('yarn-client')\\\n",
    "        .appName(\"TPCH_Q5\")\\\n",
    "        .getOrCreate()\n",
    "c_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/customer\")\n",
    "c_df.createOrReplaceTempView(\"customer\")\n",
    "o_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/orders\")\n",
    "o_df.createOrReplaceTempView(\"orders\")\n",
    "l_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/lineitem\")\n",
    "l_df.createOrReplaceTempView(\"lineitem\")\n",
    "s_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/supplier\")\n",
    "s_df.createOrReplaceTempView(\"supplier\")\n",
    "n_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/nation\")\n",
    "n_df.createOrReplaceTempView(\"nation\")\n",
    "r_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/region\")\n",
    "r_df.createOrReplaceTempView(\"region\")\n",
    "query = \"select \\\n",
    "           n_name, \\\n",
    "           sum(l_extendedprice * (1 - l_discount)) as revenue \\\n",
    "         from \\\n",
    "           customer, \\\n",
    "           orders, \\\n",
    "           lineitem, \\\n",
    "           supplier, \\\n",
    "           nation, \\\n",
    "           region \\\n",
    "         where \\\n",
    "           c_custkey = o_custkey \\\n",
    "           and l_orderkey = o_orderkey \\\n",
    "           and l_suppkey = s_suppkey \\\n",
    "           and c_nationkey = s_nationkey \\\n",
    "           and s_nationkey = n_nationkey \\\n",
    "           and n_regionkey = r_regionkey \\\n",
    "           and r_name = 'ASIA' \\\n",
    "           and o_orderdate >= date '1994-01-01' \\\n",
    "           and o_orderdate < date '1995-01-01' \\\n",
    "         group by \\\n",
    "           n_name \\\n",
    "         order by \\\n",
    "           revenue desc \"\n",
    "sqlDF = spark.sql(query)\n",
    "print(\"RowBased Process\")\n",
    "%time sqlDF.show()\n",
    "%time sqlDF.show()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Query 6 #####################\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master('yarn-client')\\\n",
    "        .appName(\"TPCH_Q6\")\\\n",
    "        .getOrCreate()\n",
    "df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/lineitem\")\n",
    "df.createOrReplaceTempView(\"lineitem\")\n",
    "query = \"select \\\n",
    "           sum(l_extendedprice * l_discount) as revenue \\\n",
    "         from \\\n",
    "           lineitem \\\n",
    "         where \\\n",
    "           l_shipdate >= date '1994-01-01' \\\n",
    "           and l_shipdate < date '1995-01-01' \\\n",
    "           and l_discount between 0.05 and 0.07 \\\n",
    "           and l_quantity < 24\"\n",
    "sqlDF = spark.sql(query)\n",
    "print(\"RowBased Process\")\n",
    "%time sqlDF.show()\n",
    "%time sqlDF.show()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Query 7 #####################\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master('yarn-client')\\\n",
    "        .appName(\"TPCH_Q7\")\\\n",
    "        .getOrCreate()\n",
    "s_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/supplier\")\n",
    "s_df.createOrReplaceTempView(\"supplier\")\n",
    "l_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/lineitem\")\n",
    "l_df.createOrReplaceTempView(\"lineitem\")\n",
    "o_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/orders\")\n",
    "o_df.createOrReplaceTempView(\"orders\")\n",
    "c_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/customer\")\n",
    "c_df.createOrReplaceTempView(\"customer\")\n",
    "n_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/nation\")\n",
    "n_df.createOrReplaceTempView(\"nation\")\n",
    "query = \"select \\\n",
    "           supp_nation, \\\n",
    "           cust_nation, \\\n",
    "           l_year, \\\n",
    "           sum(volume) as revenue \\\n",
    "         from \\\n",
    "           (select \\\n",
    "              n1.n_name as supp_nation, \\\n",
    "              n2.n_name as cust_nation, \\\n",
    "              year(l_shipdate) as l_year, \\\n",
    "              l_extendedprice * (1 - l_discount) as volume \\\n",
    "            from \\\n",
    "              supplier, \\\n",
    "              lineitem, \\\n",
    "              orders, \\\n",
    "              customer, \\\n",
    "              nation n1, \\\n",
    "              nation n2 \\\n",
    "            where \\\n",
    "              s_suppkey = l_suppkey \\\n",
    "              and o_orderkey = l_orderkey \\\n",
    "              and c_custkey = o_custkey \\\n",
    "              and s_nationkey = n1.n_nationkey \\\n",
    "              and c_nationkey = n2.n_nationkey \\\n",
    "              and (\\\n",
    "                (n1.n_name = 'FRANCE' and n2.n_name = 'GERMANY') \\\n",
    "                or (n1.n_name = 'GERMANY' and n2.n_name = 'FRANCE') \\\n",
    "              ) \\\n",
    "              and l_shipdate between date '1995-01-01' and date '1996-12-31' \\\n",
    "           ) as shipping \\\n",
    "         group by \\\n",
    "           supp_nation, \\\n",
    "           cust_nation, \\\n",
    "           l_year \\\n",
    "         order by \\\n",
    "           supp_nation, \\\n",
    "           cust_nation, \\\n",
    "           l_year\"\n",
    "sqlDF = spark.sql(query)\n",
    "print(\"RowBased Process\")\n",
    "%time sqlDF.show()\n",
    "%time sqlDF.show()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Query 8 #####################\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master('yarn-client')\\\n",
    "        .appName(\"TPCH_Q8\")\\\n",
    "        .getOrCreate()\n",
    "p_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/part\")\n",
    "p_df.createOrReplaceTempView(\"part\")\n",
    "s_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/supplier\")\n",
    "s_df.createOrReplaceTempView(\"supplier\")\n",
    "l_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/lineitem\")\n",
    "l_df.createOrReplaceTempView(\"lineitem\")\n",
    "o_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/orders\")\n",
    "o_df.createOrReplaceTempView(\"orders\")\n",
    "c_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/customer\")\n",
    "c_df.createOrReplaceTempView(\"customer\")\n",
    "n_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/nation\")\n",
    "n_df.createOrReplaceTempView(\"nation\")\n",
    "r_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/region\")\n",
    "r_df.createOrReplaceTempView(\"region\")\n",
    "query = \"select \\\n",
    "           o_year, \\\n",
    "           sum(case when nation = ':1' then volume else 0 end) / sum(volume) as mkt_share \\\n",
    "         from \\\n",
    "           (select \\\n",
    "              extract(year from o_orderdate) as o_year, \\\n",
    "              l_extendedprice * (1 - l_discount) as volume, \\\n",
    "              n2.n_name as nation \\\n",
    "            from \\\n",
    "              part, \\\n",
    "              supplier, \\\n",
    "              lineitem, \\\n",
    "              orders, \\\n",
    "              customer, \\\n",
    "              nation n1, \\\n",
    "              nation n2, \\\n",
    "              region \\\n",
    "            where \\\n",
    "              p_partkey = l_partkey \\\n",
    "              and s_suppkey = l_suppkey \\\n",
    "              and l_orderkey = o_orderkey \\\n",
    "              and o_custkey = c_custkey \\\n",
    "              and c_nationkey = n1.n_nationkey \\\n",
    "              and n1.n_regionkey = r_regionkey \\\n",
    "              and r_name = ':2' \\\n",
    "              and s_nationkey = n2.n_nationkey \\\n",
    "              and o_orderdate between date '1995-01-01' and date '1996-12-31' \\\n",
    "              and p_type = ':3' \\\n",
    "            ) as all_nations \\\n",
    "         group by \\\n",
    "           o_year \\\n",
    "         order by \\\n",
    "           o_year\"\n",
    "sqlDF = spark.sql(query)\n",
    "print(\"RowBased Process\")\n",
    "%time sqlDF.show()\n",
    "%time sqlDF.show()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###################### Query 9 #####################\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master('yarn-client')\\\n",
    "        .appName(\"TPCH_Q9\")\\\n",
    "        .getOrCreate()\n",
    "p_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/part\")\n",
    "p_df.createOrReplaceTempView(\"part\")\n",
    "s_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/supplier\")\n",
    "s_df.createOrReplaceTempView(\"supplier\")\n",
    "l_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/lineitem\")\n",
    "l_df.createOrReplaceTempView(\"lineitem\")\n",
    "ps_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/partsupp\")\n",
    "ps_df.createOrReplaceTempView(\"partsupp\")\n",
    "o_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/orders\")\n",
    "o_df.createOrReplaceTempView(\"orders\")\n",
    "n_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/nation\")\n",
    "n_df.createOrReplaceTempView(\"nation\")\n",
    "query = \"select \\\n",
    "           nation, \\\n",
    "           o_year, \\\n",
    "           sum(amount) as sum_profit \\\n",
    "           from \\\n",
    "             (select \\\n",
    "                n_name as nation, \\\n",
    "                year(o_orderdate) as o_year, \\\n",
    "                l_extendedprice * (1 - l_discount) - ps_supplycost * l_quantity as amount \\\n",
    "              from \\\n",
    "                part, \\\n",
    "                supplier, \\\n",
    "                lineitem, \\\n",
    "                partsupp, \\\n",
    "                orders, \\\n",
    "                nation \\\n",
    "              where \\\n",
    "                s_suppkey = l_suppkey \\\n",
    "                and ps_suppkey = l_suppkey \\\n",
    "                and ps_partkey = l_partkey \\\n",
    "                and p_partkey = l_partkey \\\n",
    "                and o_orderkey = l_orderkey \\\n",
    "                and s_nationkey = n_nationkey \\\n",
    "                and p_name like '%green%'\\\n",
    "             ) as profit \\\n",
    "           group by \\\n",
    "             nation, \\\n",
    "             o_year \\\n",
    "           order by \\\n",
    "             nation, o_year desc\"\n",
    "sqlDF = spark.sql(query)\n",
    "print(\"RowBased Process\")\n",
    "%time sqlDF.show()\n",
    "%time sqlDF.show()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Query 10 #####################\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master('yarn-client')\\\n",
    "        .appName(\"TPCH_Q10\")\\\n",
    "        .getOrCreate()\n",
    "c_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/customer\")\n",
    "c_df.createOrReplaceTempView(\"customer\")\n",
    "o_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/orders\")\n",
    "o_df.createOrReplaceTempView(\"orders\")\n",
    "l_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/lineitem\")\n",
    "l_df.createOrReplaceTempView(\"lineitem\")\n",
    "n_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/nation\")\n",
    "n_df.createOrReplaceTempView(\"nation\")\n",
    "query = \"select \\\n",
    "           c_custkey, \\\n",
    "           c_name, \\\n",
    "           sum(l_extendedprice * (1 - l_discount)) as revenue, \\\n",
    "           c_acctbal, \\\n",
    "           n_name, \\\n",
    "           c_address, \\\n",
    "           c_phone, \\\n",
    "           c_comment \\\n",
    "         from \\\n",
    "           customer, \\\n",
    "           orders, \\\n",
    "           lineitem, \\\n",
    "           nation \\\n",
    "         where \\\n",
    "           c_custkey = o_custkey \\\n",
    "           and l_orderkey = o_orderkey \\\n",
    "           and o_orderdate >= date '1993-10-01' \\\n",
    "           and o_orderdate < date '1994-01-01' \\\n",
    "           and l_returnflag = 'R' \\\n",
    "           and c_nationkey = n_nationkey \\\n",
    "         group by \\\n",
    "           c_custkey, \\\n",
    "           c_name, \\\n",
    "           c_acctbal, \\\n",
    "           c_phone, \\\n",
    "           n_name, \\\n",
    "           c_address, \\\n",
    "           c_comment \\\n",
    "         order by \\\n",
    "           revenue desc\"\n",
    "sqlDF = spark.sql(query)\n",
    "print(\"RowBased Process\")\n",
    "%time sqlDF.show(20)\n",
    "%time sqlDF.show(20)\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Query 11 #####################\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master('yarn-client')\\\n",
    "        .appName(\"TPCH_Q11\")\\\n",
    "        .getOrCreate()\n",
    "p_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/partsupp\")\n",
    "p_df.createOrReplaceTempView(\"partsupp\")\n",
    "s_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/supplier\")\n",
    "s_df.createOrReplaceTempView(\"supplier\")\n",
    "n_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/nation\")\n",
    "n_df.createOrReplaceTempView(\"nation\")\n",
    "query = \"select \\\n",
    "           ps_partkey, \\\n",
    "           sum(ps_supplycost * ps_availqty) as value \\\n",
    "         from \\\n",
    "           partsupp, \\\n",
    "           supplier, \\\n",
    "           nation \\\n",
    "         where \\\n",
    "           ps_suppkey = s_suppkey \\\n",
    "           and s_nationkey = n_nationkey \\\n",
    "           and n_name = 'GERMANY' \\\n",
    "         group by \\\n",
    "           ps_partkey \\\n",
    "         having \\\n",
    "           sum(ps_supplycost * ps_availqty) > \\\n",
    "           (select \\\n",
    "              sum(ps_supplycost * ps_availqty) * 0.0001000000 \\\n",
    "            from \\\n",
    "              partsupp, \\\n",
    "              supplier, \\\n",
    "              nation \\\n",
    "            where \\\n",
    "              ps_suppkey = s_suppkey \\\n",
    "              and s_nationkey = n_nationkey \\\n",
    "              and n_name = 'GERMANY') \\\n",
    "          order by \\\n",
    "            value desc\"\n",
    "sqlDF = spark.sql(query)\n",
    "print(\"RowBased Process\")\n",
    "%time sqlDF.show()\n",
    "%time sqlDF.show()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Query 12 #####################\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master('yarn-client')\\\n",
    "        .appName(\"TPCH_Q12\")\\\n",
    "        .getOrCreate()\n",
    "o_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/orders\")\n",
    "o_df.createOrReplaceTempView(\"orders\")\n",
    "l_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/lineitem\")\n",
    "l_df.createOrReplaceTempView(\"lineitem\")\n",
    "query = \"select \\\n",
    "           l_shipmode, \\\n",
    "           sum(case when o_orderpriority = '1-URGENT' or o_orderpriority = '2-HIGH' then 1 else 0 end) as high_line_count, \\\n",
    "           sum(case when o_orderpriority <> '1-URGENT' and o_orderpriority <> '2-HIGH' then 1 else 0 end) as low_line_count \\\n",
    "         from \\\n",
    "           orders, \\\n",
    "           lineitem \\\n",
    "         where \\\n",
    "           o_orderkey = l_orderkey \\\n",
    "           and l_shipmode in ('MAIL', 'SHIP') \\\n",
    "           and l_commitdate < l_receiptdate \\\n",
    "           and l_shipdate < l_commitdate \\\n",
    "           and l_receiptdate >= date '1994-01-01' \\\n",
    "           and l_receiptdate < date '1995-01-01' \\\n",
    "         group by \\\n",
    "           l_shipmode \\\n",
    "         order by \\\n",
    "           l_shipmode\"\n",
    "sqlDF = spark.sql(query)\n",
    "print(\"RowBased Process\")\n",
    "%time sqlDF.show()\n",
    "%time sqlDF.show()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Query 13 #####################\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master('yarn-client')\\\n",
    "        .appName(\"TPCH_Q13\")\\\n",
    "        .getOrCreate()\n",
    "c_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/customer\")\n",
    "c_df.createOrReplaceTempView(\"customer\")\n",
    "o_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/orders\")\n",
    "o_df.createOrReplaceTempView(\"orders\")\n",
    "query = \"select \\\n",
    "           c_count, \\\n",
    "           count(*) as custdist \\\n",
    "         from \\\n",
    "           (select \\\n",
    "              c_custkey, \\\n",
    "              count(o_orderkey) as c_count \\\n",
    "            from \\\n",
    "              customer \\\n",
    "              left outer join \\\n",
    "                orders \\\n",
    "              on \\\n",
    "                c_custkey = o_custkey \\\n",
    "                and o_comment not like '%special%requests%' \\\n",
    "            group by \\\n",
    "              c_custkey) as c_orders \\\n",
    "         group by \\\n",
    "           c_count \\\n",
    "         order by \\\n",
    "           custdist desc, c_count desc\"\n",
    "sqlDF = spark.sql(query)\n",
    "print(\"RowBased Process\")\n",
    "%time sqlDF.show()\n",
    "%time sqlDF.show()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Query 14 #####################\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master('yarn-client')\\\n",
    "        .appName(\"TPCH_Q14\")\\\n",
    "        .getOrCreate()\n",
    "l_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/lineitem\")\n",
    "l_df.createOrReplaceTempView(\"lineitem\")\n",
    "p_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/part\")\n",
    "p_df.createOrReplaceTempView(\"part\")\n",
    "query = \"select \\\n",
    "           100.00 * sum( \\\n",
    "                      case when p_type like 'PROMO%' then l_extendedprice * (1 - l_discount) else 0 end \\\n",
    "                      ) / sum(l_extendedprice * (1 - l_discount)) \\\n",
    "           as promo_revenue \\\n",
    "         from \\\n",
    "           lineitem, \\\n",
    "           part \\\n",
    "         where \\\n",
    "           l_partkey = p_partkey \\\n",
    "           and l_shipdate >= date '1995-09-01' \\\n",
    "           and l_shipdate < date '1995-10-01'\"\n",
    "sqlDF = spark.sql(query)\n",
    "print(\"RowBased Process\")\n",
    "%time sqlDF.show()\n",
    "%time sqlDF.show()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Query 15 #####################\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master('yarn-client')\\\n",
    "        .appName(\"TPCH_Q15\")\\\n",
    "        .getOrCreate()\n",
    "s_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/supplier\")\n",
    "s_df.createOrReplaceTempView(\"supplier\")\n",
    "l_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/lineitem\")\n",
    "l_df.createOrReplaceTempView(\"lineitem\")\n",
    "query = \"with revenue0 as \\\n",
    "           (select \\\n",
    "              l_suppkey as supplier_no, \\\n",
    "              sum(l_extendedprice * (1 - l_discount)) as total_revenue \\\n",
    "            from \\\n",
    "              lineitem \\\n",
    "            where \\\n",
    "              l_shipdate >= date '1996-01-01' \\\n",
    "              and l_shipdate < date '1996-04-01' \\\n",
    "            group by \\\n",
    "              l_suppkey) \\\n",
    "          select \\\n",
    "            s_suppkey, \\\n",
    "            s_name, \\\n",
    "            s_address, \\\n",
    "            s_phone, \\\n",
    "            total_revenue \\\n",
    "          from \\\n",
    "            supplier, \\\n",
    "            revenue0 \\\n",
    "          where \\\n",
    "            s_suppkey = supplier_no \\\n",
    "            and total_revenue = \\\n",
    "            (select \\\n",
    "               max(total_revenue) \\\n",
    "             from \\\n",
    "               revenue0) \\\n",
    "          order by \\\n",
    "            s_suppkey\"\n",
    "sqlDF = spark.sql(query)\n",
    "print(\"RowBased Process\")\n",
    "%time sqlDF.show()\n",
    "%time sqlDF.show()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Query 16 #####################\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master('yarn-client')\\\n",
    "        .appName(\"TPCH_Q16\")\\\n",
    "        .getOrCreate()\n",
    "c_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/partsupp\")\n",
    "c_df.createOrReplaceTempView(\"partsupp\")\n",
    "l_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/part\")\n",
    "l_df.createOrReplaceTempView(\"part\")\n",
    "o_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/supplier\")\n",
    "o_df.createOrReplaceTempView(\"supplier\")\n",
    "query = \"select \\\n",
    "           p_brand, \\\n",
    "           p_type, \\\n",
    "           p_size, \\\n",
    "           count(distinct ps_suppkey) as supplier_cnt \\\n",
    "         from \\\n",
    "           partsupp, \\\n",
    "           part \\\n",
    "         where \\\n",
    "           p_partkey = ps_partkey \\\n",
    "           and p_brand <> 'Brand#45' \\\n",
    "           and p_type not like 'MEDIUM POLISHED%' \\\n",
    "           and p_size in (49, 14, 23, 45, 19, 3, 36, 9) \\\n",
    "           and ps_suppkey not in \\\n",
    "           (select \\\n",
    "              s_suppkey \\\n",
    "            from \\\n",
    "              supplier \\\n",
    "            where \\\n",
    "              s_comment like '%Customer%Complaints%') \\\n",
    "         group by \\\n",
    "           p_brand, \\\n",
    "           p_type, \\\n",
    "           p_size \\\n",
    "         order by \\\n",
    "           supplier_cnt desc, p_brand, p_type, p_size\"\n",
    "sqlDF = spark.sql(query)\n",
    "print(\"RowBased Process\")\n",
    "%time sqlDF.show()\n",
    "%time sqlDF.show()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Query 17 #####################\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master('yarn-client')\\\n",
    "        .appName(\"TPCH_Q17\")\\\n",
    "        .getOrCreate()\n",
    "l_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/lineitem\")\n",
    "l_df.createOrReplaceTempView(\"lineitem\")\n",
    "p_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/part\")\n",
    "p_df.createOrReplaceTempView(\"part\")\n",
    "query = \"select \\\n",
    "           sum(l_extendedprice) / 7.0 as avg_yearly \\\n",
    "         from \\\n",
    "           lineitem, \\\n",
    "           part \\\n",
    "         where \\\n",
    "           p_partkey = l_partkey \\\n",
    "           and p_brand = 'Brand#23' \\\n",
    "           and p_container = 'MED BOX' \\\n",
    "           and l_quantity < ( \\\n",
    "             select \\\n",
    "               0.2 * avg(l_quantity) \\\n",
    "             from \\\n",
    "               lineitem \\\n",
    "             where \\\n",
    "               l_partkey = p_partkey)\"\n",
    "sqlDF = spark.sql(query)\n",
    "print(\"RowBased Process\")\n",
    "%time sqlDF.show()\n",
    "%time sqlDF.show()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Query 18 #####################\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master('yarn-client')\\\n",
    "        .appName(\"TPCH_Q18\")\\\n",
    "        .getOrCreate()\n",
    "c_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/customer\")\n",
    "c_df.createOrReplaceTempView(\"customer\")\n",
    "l_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/lineitem\")\n",
    "l_df.createOrReplaceTempView(\"lineitem\")\n",
    "o_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/orders\")\n",
    "o_df.createOrReplaceTempView(\"orders\")\n",
    "query = \"select \\\n",
    "           c_name, \\\n",
    "           c_custkey, \\\n",
    "           o_orderkey, \\\n",
    "           o_orderdate, \\\n",
    "           o_totalprice, \\\n",
    "           sum(l_quantity) \\\n",
    "         from \\\n",
    "           customer, \\\n",
    "           orders, \\\n",
    "           lineitem \\\n",
    "         where \\\n",
    "           o_orderkey in ( \\\n",
    "           select \\\n",
    "             l_orderkey \\\n",
    "           from \\\n",
    "             lineitem \\\n",
    "           group by \\\n",
    "             l_orderkey \\\n",
    "           having \\\n",
    "             sum(l_quantity) > 300 )\\\n",
    "           and c_custkey = o_custkey \\\n",
    "           and o_orderkey = l_orderkey \\\n",
    "          group by \\\n",
    "            c_name, \\\n",
    "            c_custkey, \\\n",
    "            o_orderkey, \\\n",
    "            o_orderdate, \\\n",
    "            o_totalprice \\\n",
    "          order by \\\n",
    "            o_totalprice desc, o_orderdate\"\n",
    "sqlDF = spark.sql(query)\n",
    "print(\"RowBased Process\")\n",
    "%time sqlDF.show(100)\n",
    "%time sqlDF.show(100)\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Query 19 #####################\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master('yarn-client')\\\n",
    "        .appName(\"TPCH_Q19\")\\\n",
    "        .getOrCreate()\n",
    "l_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/lineitem\")\n",
    "l_df.createOrReplaceTempView(\"lineitem\")\n",
    "p_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/part\")\n",
    "p_df.createOrReplaceTempView(\"part\")\n",
    "query = \"select \\\n",
    "           sum(l_extendedprice* (1 - l_discount)) as revenue \\\n",
    "         from \\\n",
    "           lineitem, \\\n",
    "           part where ( \\\n",
    "             p_partkey = l_partkey \\\n",
    "             and p_brand = 'Brand#12' \\\n",
    "             and p_container in ('SM CASE', 'SM BOX', 'SM PACK', 'SM PKG') \\\n",
    "             and l_quantity >= 1 \\\n",
    "             and l_quantity <= 1 + 10 \\\n",
    "             and p_size between 1 and 5 \\\n",
    "             and l_shipmode in ('AIR', 'AIR REG') \\\n",
    "             and l_shipinstruct = 'DELIVER IN PERSON' \\\n",
    "           ) or ( \\\n",
    "             p_partkey = l_partkey \\\n",
    "             and p_brand = 'Brand#23' \\\n",
    "             and p_container in ('MED BAG', 'MED BOX', 'MED PKG', 'MED PACK') \\\n",
    "             and l_quantity >= 10 \\\n",
    "             and l_quantity <= 10 + 10 \\\n",
    "             and p_size between 1 and 10 \\\n",
    "             and l_shipmode in ('AIR', 'AIR REG') \\\n",
    "             and l_shipinstruct = 'DELIVER IN PERSON' \\\n",
    "           ) or ( \\\n",
    "             p_partkey = l_partkey \\\n",
    "             and p_brand = 'Brand#34' \\\n",
    "             and p_container in ('LG CASE', 'LG BOX', 'LG PACK', 'LG PKG') \\\n",
    "             and l_quantity >= 20 \\\n",
    "             and l_quantity <= 20 + 10 \\\n",
    "             and p_size between 1 and 15 \\\n",
    "             and l_shipmode in ('AIR', 'AIR REG') \\\n",
    "             and l_shipinstruct = 'DELIVER IN PERSON' \\\n",
    "           )\"\n",
    "sqlDF = spark.sql(query)\n",
    "print(\"RowBased Process\")\n",
    "%time sqlDF.show(20)\n",
    "%time sqlDF.show(20)\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Query 20 #####################\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master('yarn-client')\\\n",
    "        .appName(\"TPCH_Q20\")\\\n",
    "        .getOrCreate()\n",
    "s_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/supplier\")\n",
    "s_df.createOrReplaceTempView(\"supplier\")\n",
    "n_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/nation\")\n",
    "n_df.createOrReplaceTempView(\"nation\")\n",
    "ps_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/partsupp\")\n",
    "ps_df.createOrReplaceTempView(\"partsupp\")\n",
    "p_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/part\")\n",
    "p_df.createOrReplaceTempView(\"part\")\n",
    "l_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/lineitem\")\n",
    "l_df.createOrReplaceTempView(\"lineitem\")\n",
    "query = \"select \\\n",
    "           s_name, \\\n",
    "           s_address \\\n",
    "         from \\\n",
    "           supplier, \\\n",
    "           nation \\\n",
    "         where \\\n",
    "           s_suppkey in \\\n",
    "             (select \\\n",
    "                ps_suppkey \\\n",
    "              from \\\n",
    "                partsupp \\\n",
    "              where \\\n",
    "                ps_partkey in \\\n",
    "                  (select \\\n",
    "                     p_partkey \\\n",
    "                   from \\\n",
    "                     part \\\n",
    "                   where \\\n",
    "                     p_name like 'forest%') \\\n",
    "                and ps_availqty > \\\n",
    "                  (select \\\n",
    "                     0.5 * sum(l_quantity) \\\n",
    "                   from \\\n",
    "                     lineitem \\\n",
    "                   where \\\n",
    "                     l_partkey = ps_partkey \\\n",
    "                     and l_suppkey = ps_suppkey \\\n",
    "                     and l_shipdate >= date '1994-01-01' \\\n",
    "                     and l_shipdate <  date '1995-01-01')\\\n",
    "             ) \\\n",
    "           and s_nationkey = n_nationkey \\\n",
    "           and n_name = 'CANADA' \\\n",
    "           order by \\\n",
    "             s_name\"\n",
    "sqlDF = spark.sql(query)\n",
    "print(\"RowBased Process\")\n",
    "%time sqlDF.show()\n",
    "%time sqlDF.show()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Query 21 #####################\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master('yarn-client')\\\n",
    "        .appName(\"TPCH_Q21\")\\\n",
    "        .getOrCreate()\n",
    "s_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/supplier\")\n",
    "s_df.createOrReplaceTempView(\"supplier\")\n",
    "l_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/lineitem\")\n",
    "l_df.createOrReplaceTempView(\"lineitem\")\n",
    "o_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/orders\")\n",
    "o_df.createOrReplaceTempView(\"orders\")\n",
    "n_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/nation\")\n",
    "n_df.createOrReplaceTempView(\"nation\")\n",
    "p_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/part\")\n",
    "p_df.createOrReplaceTempView(\"part\")\n",
    "query = \"select \\\n",
    "           s_name, \\\n",
    "           count(*) as numwait \\\n",
    "         from \\\n",
    "           supplier, \\\n",
    "           lineitem l1, \\\n",
    "           orders, \\\n",
    "           nation \\\n",
    "         where \\\n",
    "           s_suppkey = l1.l_suppkey \\\n",
    "           and o_orderkey = l1.l_orderkey \\\n",
    "           and o_orderstatus = 'F' \\\n",
    "           and l1.l_receiptdate > l1.l_commitdate \\\n",
    "           and exists ( \\\n",
    "             select \\\n",
    "               * \\\n",
    "             from \\\n",
    "               lineitem l2 \\\n",
    "             where \\\n",
    "               l2.l_orderkey = l1.l_orderkey \\\n",
    "               and l2.l_suppkey <> l1.l_suppkey \\\n",
    "           ) and not exists ( \\\n",
    "             select \\\n",
    "               * \\\n",
    "             from \\\n",
    "               lineitem l3 \\\n",
    "             where \\\n",
    "               l3.l_orderkey = l1.l_orderkey \\\n",
    "               and l3.l_suppkey <> l1.l_suppkey \\\n",
    "               and l3.l_receiptdate > l3.l_commitdate\\\n",
    "           ) and s_nationkey = n_nationkey \\\n",
    "           and n_name = 'SAUDI ARABIA' \\\n",
    "           group by \\\n",
    "             s_name \\\n",
    "           order by \\\n",
    "             numwait desc, s_name\"\n",
    "sqlDF = spark.sql(query)\n",
    "print(\"RowBased Process\")\n",
    "%time sqlDF.show()\n",
    "%time sqlDF.show()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Query 22 #####################\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master('yarn-client')\\\n",
    "        .appName(\"TPCH_Q22\")\\\n",
    "        .getOrCreate()\n",
    "c_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/customer\")\n",
    "c_df.createOrReplaceTempView(\"customer\")\n",
    "o_df = spark.read.format(\"parquet\").load(\"/orin_tpchnp_100/orders\")\n",
    "o_df.createOrReplaceTempView(\"orders\")\n",
    "query = \"select \\\n",
    "           cntrycode, \\\n",
    "           count(*) as numcust, \\\n",
    "           sum(c_acctbal) as totacctbal \\\n",
    "         from \\\n",
    "           ( \\\n",
    "             select \\\n",
    "               substring(c_phone, 1, 2) as cntrycode, \\\n",
    "               c_acctbal \\\n",
    "             from \\\n",
    "               customer \\\n",
    "             where \\\n",
    "               substring(c_phone, 1, 2) in \\\n",
    "                 ('13', '31', '23', '29', '30', '18', '17') \\\n",
    "               and c_acctbal > ( \\\n",
    "                 select \\\n",
    "                   avg(c_acctbal) \\\n",
    "                 from \\\n",
    "                   customer \\\n",
    "                 where \\\n",
    "                   c_acctbal > 0.00 \\\n",
    "                   and substring(c_phone, 1, 2) in \\\n",
    "                     ('13', '31', '23', '29', '30', '18', '17') \\\n",
    "               ) \\\n",
    "               and not exists ( \\\n",
    "                 select \\\n",
    "                   * \\\n",
    "                 from \\\n",
    "                   orders \\\n",
    "                 where \\\n",
    "                   o_custkey = c_custkey \\\n",
    "               ) \\\n",
    "           ) as custsale \\\n",
    "         group by \\\n",
    "           cntrycode \\\n",
    "         order by \\\n",
    "           cntrycode\"\n",
    "sqlDF = spark.sql(query)\n",
    "print(\"RowBased Process\")\n",
    "%time sqlDF.show()\n",
    "%time sqlDF.show()\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
